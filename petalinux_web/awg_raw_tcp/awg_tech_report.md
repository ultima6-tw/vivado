# 專案技術報告：基於 Zynq SoC 的高效能、即時任意波形產生器系統

**報告版本**: 1.0
**日期**: 2025年9月25日

---

### **摘要 (Abstract)**

本報告詳細闡述了一個基於 Xilinx Zynq SoC 平台開發的高效能任意波形產生器 (AWG) 系統。此系統旨在解決傳統儀器在長波形串流與即時互動性方面的不足。我們採用了軟硬協同設計理念，利用 Zynq 平台的處理器系統 (PS) 運行一個客製化的多執行緒 C 語言伺服器，負責網路通訊與高層次序列控制；利用可程式化邏輯 (PL) 執行底層的精確時序訊號生成。

系統透過乙太網路接收遠端客戶端（Python/LabVIEW）的指令，採用雙緩衝區（Ping-Pong Buffer）機制，實現了無間斷的連續波形輸出。通訊協定被設計為分離的控制、資料與通知平面，確保了系統的穩定性與高效能。報告中也詳細記錄了開發過程中遇到的關鍵挑戰，如多執行緒死鎖、網路吞吐率瓶頸等，並提出了對應的解決方案。

最終效能評估顯示，優化後的資料傳輸速率相比初步設計提升了超過兩個數量級，證明了本系統架構在處理高速、複雜波形串流任務上的優越性。

---

### **1. 緒論 (Introduction)**

#### **1.1. 專案目標**
本專案的核心目標是設計並實現一個能夠透過網路遠端控制的任意波形產生器。該系統需滿足以下關鍵要求：
* **連續無間斷輸出**: 能夠長時間連續輸出波形，中間無任何時間間隙。
* **高吞吐率**: 能夠快速從遠端客戶端預載入大量的波形數據。
* **即時性與 flexibilidad**: 具備快速改變波形序列的能力，並為未來的即時反饋控制預留架構基礎。

#### **1.2. 核心挑戰**
* **軟硬體整合**: 如何高效地在 Zynq 的 ARM 處理器 (PS) 與 FPGA (PL) 之間傳遞數據與指令。
* **網路效能**: 如何克服 TCP/IP 網路延遲，確保數據能快速、可靠地載入到嵌入式系統的記憶體中。
* **系統穩定性**: 如何在多執行緒的嵌入式 Linux 環境下，確保伺服器的長期穩定運行，避免死鎖和競爭條件。

#### **1.3. 技術棧 (Technology Stack)**
* **硬體平台**: Xilinx Zynq-7000 SoC (型號: wavegenz7)
* **作業系統**: 嵌入式 Linux (Petalinux)
* **伺服器端**: C 語言，使用 POSIX Threads (Pthreads) 進行多執行緒程式設計
* **客戶端**: Python 3 (未來規劃 LabVIEW)
* **通訊協定**: 基於 TCP/IP 的客製化二進位協定

---

### **2. 系統架構 (System Architecture)**

#### **2.1. 總體設計**
本系統為 Client-Server 架構。客戶端負責波形序列的定義與高層次控制，伺服器端負責解析指令、管理記憶體並驅動硬體。

`[Client] <--> [TCP/IP Network] <--> [Zynq PS: C Server] <--> [AXI Bus] <--> [Zynq PL: AWG Core]`

#### **2.2. 控制、資料與通知平面**
為確保系統穩定與高效，通訊被劃分為三個邏輯平面：
* **控制/資料平面 (Port 9100)**: 用於傳送控制指令 (`B`, `E`, `Z`, `X`) 和主要的波形數據 (`P`)。
* **通知平面 (Port 9101)**: 一個獨立的 TCP 連線，由伺服器主動向客戶端發送狀態更新（如 `LIST<id>:IDLE`），實現非同步事件通知。

#### **2.3. 雙緩衝區串流機制**
為實現無間斷輸出，系統在 DDR 記憶體中劃分了兩個波形列表緩衝區 (`list 0`, `list 1`)。FPGA 播放其中一個緩衝區的數據時，伺服器可以透過網路安全地預載入另一個閒置的緩衝區，播放完畢後原子性地切換，達成無縫串流。

#### **2.4. 軟硬協同設計理念**
本系統充分利用 Zynq SoC 的優勢，進行明確的任務分工：
* **ARM 處理器 (PS)**: 作為**控制平面**，負責靈活但非即時的任務，如網路通訊、協定解析、檔案系統管理、以及**微秒級**的波形幀序列控制。
* **FPGA (PL)**: 作為**資料平面**，負責執行對時序要求極高的任務，如**奈秒級**的時脈生成、數位類比轉換 (DAC) 驅動和精確的波形輸出。

---

### **3. 通訊協定設計**

#### **3.1. 控制通道 (Port 9100)**

| 指令 | 格式 (Bytes) | 說明 |
| :--- | :--- | :--- |
| **B**egin | `0x42` `list_id(1)` `total_frames(4)` | 開始一個列表的定義。 |
| **P**ush | `0x50` `list_id(1)` `word_count(2)` `words(N*4)` | 推送一個 frame 的數據。 |
| **E**nd | `0x45` `list_id(1)` | 結束一個列表的定義，標記為就dures。 |
| **Z**ero | `0x5A` | 重置伺服器狀態，清空所有列表。 |
| **X**-Shutdown | `0x58` | 命令嵌入式系統執行安全關機。 |

*(註：所有多位元組數字均採用 Big-Endian/網路位元組順序)*

#### **3.2. 通知通道 (Port 9101)**
採用基於換行符 (`\n`) 的 ASCII 字串訊息。格式為 `LIST<id>:<STATE>`，例如 `LIST0:IDLE`。

---

### **4. 實作細節與關鍵挑戰解決方案**

#### **4.1. C 伺服器：穩定性與安全性**
* **多執行緒模型**: 採用主執行緒監聽網路連線，為每個客戶端建立一個服務執行緒 (`serve_client`)，同時由一個獨立的播放執行緒 (`player_thread`) 負責驅動硬體，實現了職責分離。
* **安全關機程序**: 設計了嚴謹的關機順序，先停止網路服務並回收執行緒，再執行硬體清空任務，最後停止播放執行緒，徹底解決了多個版本的關機死鎖問題。
* **緩衝區安全**: 在 `do_preload_push` 中對客戶端傳來的 `count` 值進行了嚴格的邊界檢查，防止了緩衝區溢位風險。同時在 `do_preload_begin` 中增加了對 `total_frames` 的上限檢查，防止了阻斷服務攻擊 (DoS)。

#### **4.2. Python 客戶端：效能優化**
* **問題**: 初版客戶端逐筆發送 frame (`op_P_push` in a loop)，導致 `nframes=2000` 時傳輸時間長達 2 秒，效能極低。
* **原因**: 網路延遲和系統呼叫開銷成為瓶頸。
* **解決方案**: 改用**批次處理 (Batching)** 模式。在客戶端記憶體中將 2000 個 `P` 指令封包拼接成一個巨大的 `bytes` 物件，然後透過一次 `sendall()` 呼叫全部送出。
* **成果**: 傳輸時間從 **~2000 毫秒** 大幅縮短至 **<50 毫秒**，效能提升超過 **40 倍**。

#### **4.3. 即時控制模式的探討**
* **軟體驅動 (目前實作)**: 由 `player_thread` 以 `G.period_us` (目前為 1ms) 的間隔，將 frame 推送給 PL。此模式適用於毫秒至數十微秒等級的控制，但受限於 Linux 系統排程抖動 (Jitter)。
* **硬體驅動 (未來方向)**: 應在 PL 中設計一個硬體序列器 (Sequencer)，由 PS 預載入「指令清單」而非原始數據。PL 可根據此清單，以奈秒級的精確度自主執行複雜序列。這是達到微秒以下即時控制的必經之路。

---

### **5. 結論與未來展望**

本專案成功打造了一個高效能、高靈活性的 AWG 系統核心。其軟硬協同設計的架構，使其在處理長序列波形串流和客製化即時控制方面，展現出超越傳統商用儀器的潛力。

**未來工作建議**:
1.  **開發 LabVIEW 圖形化介面**: 提供更友善的使用者體驗。
2.  **實作硬體序列器**: 將系統的即時控制能力提升至微秒甚至奈秒等級。
3.  **設計與驗證類比前端**: 完成從數位到高品質類比訊號輸出的最後一哩路。

---